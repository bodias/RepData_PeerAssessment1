find.package("devtools")
install.packages("devtools")
library(devtools)
install.packages("KernSmooth")
library(httr)
oauth_endpoint("github")
oauth_endpoints("github")
myapp <- oauth_app("courseratest",key="f933f59516fd368c82ba",secret = "82d84a00d9cd2b75bb809d33c01b2cd07cd14177")
github_token = <- oauth2.0_token(oauth_endpoints("github"),myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
install.packages("httpuv")
library(httr)
myapp <- oauth_app("courseratest",key="f933f59516fd368c82ba",secret = "047fb0a04d9333aa5c7e943e0472b7ec81d5f314")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos",gtoken)
stop_for_status(req)
content(req)
content(req)
library(jsonlite)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,]
json2[1,json2$name == "datasharing"]
json2[json2$name == "datasharing"]
json2[,2]
json2[7,]
json2[7,json2$created_at]
library(sqldf)
library(httr)
myapp <- oauth_app("courseratest",key="f933f59516fd368c82ba",secret = "047fb0a04d9333aa5c7e943e0472b7ec81d5f314")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
library(jsonlite)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
json2
json2[7,]
library(dplyr)
getwd()
#load feature file which will be user to label the X_train and X_test files
features <- read.table(file="./UCI HAR Dataset/features.txt")
source('C:/Users/braian.dias/github/data-science/data-science/run_analysis.R')
library(dplyr)
getwd()
#load feature file which will be user to label the X_train and X_test files
features <- read.table(file="./UCI HAR Dataset/features.txt")
library(lattice)
library(datasets)
library(ggplot2)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
3^3
x <- 1:10
if(x > 5) x<- 0
directory <- "C:\\Users\\braian.dias\\mot-git\\ngs_test\\download\\"
directory[-1]
directory[2]
directory[3]
rm(directory)
id <- 1:332
id[2:]
length(id)
id[2:length(id)-1]
id[3:length(id)-1]
id[1:length(id)-1]
id[2:length(id)-1]
id
id[0]
id[2]
id[1]
id[2:length(id)-1]
id[3:length(id)-1]
id[4:length(id)-1]
id[4:length(id)]
id[2:length(id)]
install.packages("bigrquery")
project <- "motorola.com:sandbox"
sql <- "SELECT * FROM [motorola.com:sandbox:braian.ft_result_cloudsql] LIMIT 1000"
library(bigrquery)
resultset <- query_exec(sql,project = project)
head(resultset)
names(resultset)
summary(resultset)
desc(resultset)
set.seed(1)
rpois(5,2)
system.time(rpois(5,2))
library(datasets)
Rprof()
y <- 1
x1 <- 2
x2<- 5
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
summaryRprof()
summaryRprof()
summaryRprof()
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
summaryRprof()
1 * 0.1+2*0.2+3*0.3+4*0.4
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
sum(w(x-0.300)^2)
sum(w(x-0.300)^2)
sum(w*(x-0.300)^2)
2^2
2^3
sum(w*(x-0.1471)^2)
sum(w*(x-0.0025)^2)
sum(w*(x-1.077)^2)
?optmize
?optimize
lm(x ~ rep(1,length(x))-1, weights = w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
?lm
lm(y ~ x)
lm(y ~ x -1)
?I
data("mtcars")
data(mtcars)
str(mtcars)
lm( mpg ~ wt, data = mtcars)
lm( mpg ~ wt - 1, data = mtcars)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
scale(x)
xn <- scale(x)
colMeans(xn)
x
colMeans(x)
mean(x)
xn
xn[1:5,1]
mean(xn[1:5,1])
sd(xn[1:5,1])
var(xn[1:5,1])
?var
?scale
mean(1:4)
var(xn[1:5,1])
mean(xn)
mean(x)
sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ x)
?rnorm
out <- rnorm(10,mean=0)
pre <- rnorm(10,mean=0)
lm(out ~ pre)
library(ggplot2)
cor(out,pre)
?cor
lm( pre ~ out)
lm(out ~ pre -1)
lm(out ~ pre )
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
setwd("C:\\Users\\braian.dias\\github\\datasciencecoursera\\RepData_PeerAssessment1")
source("code.r")
new[1800:2100,]
class(new$weekday)
dim(new$weekday)
str(new)
newdaily <- group_by(new,interval,weekday)
newdaily <- summarise(newdaily,avgsteps = mean(steps,na.rm = TRUE))
par(mfrow=c(2,1))
replicate(2,{
plot(newdaily$interval,newdaily$weekday[newdaily$weekday=="weekend"],type = 'l')
plot(newdaily$interval,newdaily$weekday[newdaily$weekday=="weekday"],type = 'l')
}
)
library(ggplot2)
qplot(interval,avgsteps,data=newdaily,geom="line")
qplot(interval,avgsteps,data=newdaily,geom="line",facets = weekday ~ .)
daily[order(avgsteps),decreasing=TRUE][1]
daily[order(avgsteps),decreasing=TRUE]
daily[order(avgsteps,decreasing=TRUE)]
names(daily)
daily[order(daily$avgsteps,decreasing=TRUE)]
daily[order(daily$avgsteps,decreasing=TRUE)][1]
daily[order(daily$avgsteps,decreasing=TRUE)] %% daily[1]
daily[order(daily$avgsteps,decreasing=TRUE)] >> daily[1]
dailyordered <- daily[order(daily$avgsteps,decreasing=TRUE)] >>
dailyordered <- daily[order(daily$avgsteps,decreasing=TRUE)]
dailyordered <- daily[order(daily$avgsteps,decreasing=TRUE),]
head(dailyordered)
daily[order(daily$avgsteps,decreasing=TRUE),][1]
daily[order(daily$avgsteps,decreasing=TRUE),][1,1]
daily[order(daily$avgsteps,decreasing=TRUE),][1,"avgsteps"]
daily[order(daily$avgsteps,decreasing=TRUE),][1,"interval"]
knit2html()
library(knitr)
knit2html()
library(markdown)
